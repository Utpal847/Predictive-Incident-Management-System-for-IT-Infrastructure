{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"15i0OmUyZOKi9Az5m27Qv7s_ZvLiiRbPe","authorship_tag":"ABX9TyMgsiJ2o1qXE41KIMvo7bIe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fed747f725974bb29cbe0447d52ba9d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1778b5775dc4d4a96964aa5d57a1bbd","IPY_MODEL_056a5da6475f452f9d24d46b1748773b","IPY_MODEL_36a8e8b1195a46b586bb2c77f9bb138e"],"layout":"IPY_MODEL_2555b96fc9a84a7f8d4649752c45a138"}},"a1778b5775dc4d4a96964aa5d57a1bbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfe94cab223b4fdaa3322355e63ffd9c","placeholder":"​","style":"IPY_MODEL_80f594478ecd47b18adff0e73e3f10b0","value":"tokenizer_config.json: 100%"}},"056a5da6475f452f9d24d46b1748773b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d785c34105a24b61830cf08659efe2ed","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eed1b850d8ec473abdfe3ad5785b791a","value":48}},"36a8e8b1195a46b586bb2c77f9bb138e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58bc4bba92fc4779a9f898b0438b5f8a","placeholder":"​","style":"IPY_MODEL_ee158cd9198a44378e5f7c97e24e1c21","value":" 48.0/48.0 [00:00&lt;00:00, 3.30kB/s]"}},"2555b96fc9a84a7f8d4649752c45a138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfe94cab223b4fdaa3322355e63ffd9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80f594478ecd47b18adff0e73e3f10b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d785c34105a24b61830cf08659efe2ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed1b850d8ec473abdfe3ad5785b791a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58bc4bba92fc4779a9f898b0438b5f8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee158cd9198a44378e5f7c97e24e1c21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8aef5a72dba4cbb98b839b10eb8cf75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d871efec4424e2a9b56f3e9699e9620","IPY_MODEL_bf9444e20c8b406192ed527eb0041852","IPY_MODEL_cd7525614e914088a837e21449d2272d"],"layout":"IPY_MODEL_46bd55068bc842508d6d4626195890cd"}},"7d871efec4424e2a9b56f3e9699e9620":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bfc6b650fa54c72a436aaa159954a1e","placeholder":"​","style":"IPY_MODEL_40a577599d904d36b05b891a570a9662","value":"vocab.txt: 100%"}},"bf9444e20c8b406192ed527eb0041852":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_328465b02ded49629c14fd3de172dc36","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65ccf576d14a4bf88e023f99424939bf","value":231508}},"cd7525614e914088a837e21449d2272d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3689df8607004859ae7879874ba72b24","placeholder":"​","style":"IPY_MODEL_1017c05f031e4b6b9fec9c8f9cbc1db3","value":" 232k/232k [00:00&lt;00:00, 4.86MB/s]"}},"46bd55068bc842508d6d4626195890cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bfc6b650fa54c72a436aaa159954a1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40a577599d904d36b05b891a570a9662":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"328465b02ded49629c14fd3de172dc36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65ccf576d14a4bf88e023f99424939bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3689df8607004859ae7879874ba72b24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1017c05f031e4b6b9fec9c8f9cbc1db3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cfd3864467549fcb48ce6661aea88dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7c03fe321964827ab7e94455b159a8b","IPY_MODEL_d08a85fac4c7454d990fc5c332d87941","IPY_MODEL_a66ba950cfb04e82aa05aa4509a173b9"],"layout":"IPY_MODEL_8bd93e47fc024f44bbf23cae1097d949"}},"b7c03fe321964827ab7e94455b159a8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10fd7dc6b7d7460280e0525a2b21dca3","placeholder":"​","style":"IPY_MODEL_7d334be400c241d3af5350402accab00","value":"tokenizer.json: 100%"}},"d08a85fac4c7454d990fc5c332d87941":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0460718aec343c5a30453b49fb805bc","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8bdf1a301564775bc6a9f32bb015631","value":466062}},"a66ba950cfb04e82aa05aa4509a173b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a64ccb8507f4a0f99647c9429a9b1db","placeholder":"​","style":"IPY_MODEL_75d403bc0ffe4abc872e612a1ca7987c","value":" 466k/466k [00:00&lt;00:00, 10.3MB/s]"}},"8bd93e47fc024f44bbf23cae1097d949":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10fd7dc6b7d7460280e0525a2b21dca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d334be400c241d3af5350402accab00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0460718aec343c5a30453b49fb805bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8bdf1a301564775bc6a9f32bb015631":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a64ccb8507f4a0f99647c9429a9b1db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75d403bc0ffe4abc872e612a1ca7987c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffaba87aa5a04ce6b4c35bc70e87163c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37f9b2d086d04a4b9d921c805ad129d4","IPY_MODEL_16c50d884ff14f62aae6d4f6383b46f8","IPY_MODEL_eda6a2b42248455f9b071d5e6f632c61"],"layout":"IPY_MODEL_ff59f77334414f209929723fc16f5903"}},"37f9b2d086d04a4b9d921c805ad129d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1029ec7af85b47cb8096b9cceb613e7b","placeholder":"​","style":"IPY_MODEL_b5a461272f984ea28a40c10ce9cd1932","value":"config.json: 100%"}},"16c50d884ff14f62aae6d4f6383b46f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bc8f9d6e3814e0e96697cb324087b4b","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ee43e87094b4255a06721b7d3990e64","value":483}},"eda6a2b42248455f9b071d5e6f632c61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a17928e3c6446708e0287e87e7b71cc","placeholder":"​","style":"IPY_MODEL_a592aa9490b7435eacae3b32a0b5922d","value":" 483/483 [00:00&lt;00:00, 30.3kB/s]"}},"ff59f77334414f209929723fc16f5903":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1029ec7af85b47cb8096b9cceb613e7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5a461272f984ea28a40c10ce9cd1932":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bc8f9d6e3814e0e96697cb324087b4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ee43e87094b4255a06721b7d3990e64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a17928e3c6446708e0287e87e7b71cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a592aa9490b7435eacae3b32a0b5922d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03e00e27d5544f289384e18fc1be8ce6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a5e202f917148d0a78f4bda5f885aea","IPY_MODEL_20a77f4e81ce4a259958169cc66b72c4","IPY_MODEL_006af95ac8074ee28bdd6b8e80dd3a82"],"layout":"IPY_MODEL_14c12dc6532241e4afaffe42f5393952"}},"0a5e202f917148d0a78f4bda5f885aea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb2173704d5c4c6a8d38c3313054b87a","placeholder":"​","style":"IPY_MODEL_7a91e6b27bbc4cefbaddd59afa971d9f","value":"model.safetensors: 100%"}},"20a77f4e81ce4a259958169cc66b72c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_751fde1a1d02473e879d71e3f02af865","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90bd6ecfe3944e88ae6f822551b0c884","value":267954768}},"006af95ac8074ee28bdd6b8e80dd3a82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19a252fa29c248a49b5cbb230354cf79","placeholder":"​","style":"IPY_MODEL_58151e91d31348d397bb9122c86ada2d","value":" 268M/268M [00:05&lt;00:00, 46.8MB/s]"}},"14c12dc6532241e4afaffe42f5393952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb2173704d5c4c6a8d38c3313054b87a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a91e6b27bbc4cefbaddd59afa971d9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"751fde1a1d02473e879d71e3f02af865":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90bd6ecfe3944e88ae6f822551b0c884":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19a252fa29c248a49b5cbb230354cf79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58151e91d31348d397bb9122c86ada2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ro_A2HSN3IQS","colab":{"base_uri":"https://localhost:8080/","height":336,"referenced_widgets":["fed747f725974bb29cbe0447d52ba9d8","a1778b5775dc4d4a96964aa5d57a1bbd","056a5da6475f452f9d24d46b1748773b","36a8e8b1195a46b586bb2c77f9bb138e","2555b96fc9a84a7f8d4649752c45a138","dfe94cab223b4fdaa3322355e63ffd9c","80f594478ecd47b18adff0e73e3f10b0","d785c34105a24b61830cf08659efe2ed","eed1b850d8ec473abdfe3ad5785b791a","58bc4bba92fc4779a9f898b0438b5f8a","ee158cd9198a44378e5f7c97e24e1c21","a8aef5a72dba4cbb98b839b10eb8cf75","7d871efec4424e2a9b56f3e9699e9620","bf9444e20c8b406192ed527eb0041852","cd7525614e914088a837e21449d2272d","46bd55068bc842508d6d4626195890cd","0bfc6b650fa54c72a436aaa159954a1e","40a577599d904d36b05b891a570a9662","328465b02ded49629c14fd3de172dc36","65ccf576d14a4bf88e023f99424939bf","3689df8607004859ae7879874ba72b24","1017c05f031e4b6b9fec9c8f9cbc1db3","4cfd3864467549fcb48ce6661aea88dd","b7c03fe321964827ab7e94455b159a8b","d08a85fac4c7454d990fc5c332d87941","a66ba950cfb04e82aa05aa4509a173b9","8bd93e47fc024f44bbf23cae1097d949","10fd7dc6b7d7460280e0525a2b21dca3","7d334be400c241d3af5350402accab00","d0460718aec343c5a30453b49fb805bc","e8bdf1a301564775bc6a9f32bb015631","0a64ccb8507f4a0f99647c9429a9b1db","75d403bc0ffe4abc872e612a1ca7987c","ffaba87aa5a04ce6b4c35bc70e87163c","37f9b2d086d04a4b9d921c805ad129d4","16c50d884ff14f62aae6d4f6383b46f8","eda6a2b42248455f9b071d5e6f632c61","ff59f77334414f209929723fc16f5903","1029ec7af85b47cb8096b9cceb613e7b","b5a461272f984ea28a40c10ce9cd1932","7bc8f9d6e3814e0e96697cb324087b4b","1ee43e87094b4255a06721b7d3990e64","9a17928e3c6446708e0287e87e7b71cc","a592aa9490b7435eacae3b32a0b5922d","03e00e27d5544f289384e18fc1be8ce6","0a5e202f917148d0a78f4bda5f885aea","20a77f4e81ce4a259958169cc66b72c4","006af95ac8074ee28bdd6b8e80dd3a82","14c12dc6532241e4afaffe42f5393952","cb2173704d5c4c6a8d38c3313054b87a","7a91e6b27bbc4cefbaddd59afa971d9f","751fde1a1d02473e879d71e3f02af865","90bd6ecfe3944e88ae6f822551b0c884","19a252fa29c248a49b5cbb230354cf79","58151e91d31348d397bb9122c86ada2d"]},"executionInfo":{"status":"ok","timestamp":1752211669625,"user_tz":-330,"elapsed":292122,"user":{"displayName":"Utpal Patel","userId":"01434193021045546879"}},"outputId":"df75b7b3-8069-4254-d74e-e11743769da1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fed747f725974bb29cbe0447d52ba9d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8aef5a72dba4cbb98b839b10eb8cf75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cfd3864467549fcb48ce6661aea88dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffaba87aa5a04ce6b4c35bc70e87163c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03e00e27d5544f289384e18fc1be8ce6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|██████████| 375/375 [03:29<00:00,  1.79it/s]\n","100%|██████████| 94/94 [00:51<00:00,  1.82it/s]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from transformers import DistilBertTokenizer, DistilBertModel\n","from tqdm import tqdm\n","import torch\n","import re\n","\n","# Load dataset\n","file_path = \"/content/drive/MyDrive/log_data_reduced.csv\"\n","df = pd.read_csv(file_path)\n","\n","\n","# Preprocessing\n","df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n","df = df.dropna(subset=['Timestamp'])\n","df['Incident_Label'] = df['Incident_Label'].fillna('None')\n","df['Severity'] = df['Severity'].fillna('Low')\n","df['Suggested_Action'] = df['Suggested_Action'].replace([\n","    'None', 'none', 'NONE', None, np.nan\n","], 'No Action Required')\n","df['hour'] = df['Timestamp'].dt.hour\n","df['minute'] = df['Timestamp'].dt.minute\n","df['day_of_week'] = df['Timestamp'].dt.dayofweek\n","df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n","df['log_length'] = df['Log_Message'].astype(str).apply(len)\n","df['word_count'] = df['Log_Message'].astype(str).apply(lambda x: len(x.split()))\n","df['char_count'] = df['Log_Message'].astype(str).apply(len)\n","df['upper_case_ratio'] = df['Log_Message'].astype(str).apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n","df['error_freq'] = df['Log_Message'].str.count(r'error|fail|critical|exception', flags=re.IGNORECASE)\n","df['error_keywords'] = df['Log_Message'].astype(str).str.contains(\"error|fail|exception\", case=False).astype(int)\n","\n","# Train/test split\n","train_df, test_df = train_test_split(\n","    df, test_size=0.2, stratify=df['Suggested_Action'], random_state=42\n",")\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","train_df['Suggested_Action_Encoded'] = label_encoder.fit_transform(train_df['Suggested_Action'])\n","test_df['Suggested_Action_Encoded'] = label_encoder.transform(test_df['Suggested_Action'])\n","\n","# Normalize numerical features\n","scaler = StandardScaler()\n","numeric_cols = ['CPU_Usage (%)', 'Memory_Usage (%)']\n","train_df[numeric_cols] = scaler.fit_transform(train_df[numeric_cols])\n","test_df[numeric_cols] = scaler.transform(test_df[numeric_cols])\n","train_df['system_load'] = (train_df['CPU_Usage (%)'] + train_df['Memory_Usage (%)']) / 2\n","test_df['system_load'] = (test_df['CPU_Usage (%)'] + test_df['Memory_Usage (%)']) / 2\n","\n","# Load BERT\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","bert_model.to(device).eval()\n","\n","# Feature extraction using [CLS] token\n","def extract_features(df_part):\n","    embeddings, numeric_feats, labels = [], [], []\n","    BATCH_SIZE = 16\n","    for i in tqdm(range(0, len(df_part), BATCH_SIZE)):\n","        batch = df_part.iloc[i:i+BATCH_SIZE]\n","        texts = batch['Log_Message'].astype(str).tolist()\n","        inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n","        with torch.no_grad():\n","            outputs = bert_model(**inputs)\n","        pooled = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # [CLS] token\n","        numeric = batch[[\n","            'CPU_Usage (%)', 'Memory_Usage (%)', 'hour', 'minute', 'system_load',\n","            'day_of_week', 'is_weekend', 'log_length', 'word_count', 'char_count',\n","            'upper_case_ratio', 'error_freq', 'error_keywords'\n","        ]].values\n","        embeddings.append(pooled)\n","        numeric_feats.append(numeric)\n","        labels.append(batch['Suggested_Action_Encoded'].values)\n","    return (\n","        np.vstack(embeddings),\n","        np.vstack(numeric_feats),\n","        np.concatenate(labels)\n","    )\n","\n","X_train_bert, X_train_numeric, y_train = extract_features(train_df)\n","X_test_bert, X_test_numeric, y_test = extract_features(test_df)\n","\n","# Combine features\n","scaler_bert = StandardScaler()\n","X_train_bert_scaled = scaler_bert.fit_transform(X_train_bert)\n","X_test_bert_scaled = scaler_bert.transform(X_test_bert)\n","X_train_final = np.hstack((X_train_bert_scaled, X_train_numeric))\n","X_test_final = np.hstack((X_test_bert_scaled, X_test_numeric))\n","\n","# -------------------- Balance Data --------------------\n","X_train_bal = X_train_final\n","y_train_bal = y_train\n"]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","rf = RandomForestClassifier(\n","    n_estimators=100,\n","    max_depth=15,\n","    class_weight='balanced_subsample',\n","    random_state=42\n",")\n","rf.fit(X_train_bal, y_train_bal)\n","y_pred_rf = rf.predict(X_test_final)\n","\n","print(\"\\n📊 Random Forest Classification Report:\")\n","print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n","\n","\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","xgb = XGBClassifier(\n","    n_estimators=100,       # reduce from 200\n","    max_depth=6,            # shallower trees = faster\n","    learning_rate=0.1,      # slightly higher LR\n","    use_label_encoder=False,\n","    eval_metric='mlogloss',\n","    objective='multi:softmax',\n","    num_class=len(label_encoder.classes_),\n","\n","    random_state=42\n",")\n","\n","xgb.fit(\n","    X_train_bal,\n","    y_train_bal,\n","    eval_set=[(X_test_final, y_test)],\n","    verbose=True\n",")\n","\n","y_pred_xgb = xgb.predict(X_test_final)\n","\n","print(\"\\n📊 XGBoost Classification Report:\")\n","print(classification_report(y_test, y_pred_xgb, target_names=label_encoder.classes_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ip8fg1-ZcDd","executionInfo":{"status":"ok","timestamp":1752211830103,"user_tz":-330,"elapsed":160482,"user":{"displayName":"Utpal Patel","userId":"01434193021045546879"}},"outputId":"597d96bf-8c18-41cf-e098-9c9bbdfb4fc3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","📊 Random Forest Classification Report:\n","                                     precision    recall  f1-score   support\n","\n","               Apply security patch       0.87      1.00      0.93        58\n","                   Archive old logs       0.90      0.78      0.84        60\n","                   Block IP address       0.79      1.00      0.88        76\n","         Check database credentials       1.00      1.00      1.00        63\n","         Check network connectivity       1.00      0.79      0.88        53\n","              Clear temporary files       0.83      0.91      0.87        68\n","            Expand storage capacity       0.98      1.00      0.99        65\n","             Increase memory limits       1.00      0.96      0.98        54\n","             Inspect firewall rules       0.85      1.00      0.92        64\n","                   Investigate logs       0.98      0.58      0.73        74\n","        Investigate runaway process       1.00      1.00      1.00        74\n","                 No Action Required       1.00      1.00      1.00        54\n","          Optimize background tasks       1.00      1.00      1.00        58\n","          Optimize database queries       0.86      1.00      0.93        64\n","       Perform hardware diagnostics       0.93      1.00      0.96        78\n","                Restart application       0.99      0.99      0.99        71\n","         Restart application server       1.00      0.91      0.95        64\n","           Restart database service       1.00      0.87      0.93        78\n","           Restart network services       1.00      1.00      1.00        62\n","Restart services or scale resources       0.99      0.99      0.99        77\n","     Review heap memory allocations       0.97      0.98      0.98        60\n","           Rollback last deployment       0.97      1.00      0.98        65\n","            Scale compute resources       1.00      1.00      1.00        60\n","\n","                           accuracy                           0.95      1500\n","                          macro avg       0.95      0.95      0.94      1500\n","                       weighted avg       0.95      0.95      0.94      1500\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:28:05] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[0]\tvalidation_0-mlogloss:2.35836\n","[1]\tvalidation_0-mlogloss:2.00420\n","[2]\tvalidation_0-mlogloss:1.75915\n","[3]\tvalidation_0-mlogloss:1.56916\n","[4]\tvalidation_0-mlogloss:1.41657\n","[5]\tvalidation_0-mlogloss:1.29069\n","[6]\tvalidation_0-mlogloss:1.18261\n","[7]\tvalidation_0-mlogloss:1.09037\n","[8]\tvalidation_0-mlogloss:1.00901\n","[9]\tvalidation_0-mlogloss:0.93677\n","[10]\tvalidation_0-mlogloss:0.87283\n","[11]\tvalidation_0-mlogloss:0.81481\n","[12]\tvalidation_0-mlogloss:0.76312\n","[13]\tvalidation_0-mlogloss:0.71600\n","[14]\tvalidation_0-mlogloss:0.67305\n","[15]\tvalidation_0-mlogloss:0.63496\n","[16]\tvalidation_0-mlogloss:0.60012\n","[17]\tvalidation_0-mlogloss:0.56824\n","[18]\tvalidation_0-mlogloss:0.53935\n","[19]\tvalidation_0-mlogloss:0.51320\n","[20]\tvalidation_0-mlogloss:0.48865\n","[21]\tvalidation_0-mlogloss:0.46634\n","[22]\tvalidation_0-mlogloss:0.44554\n","[23]\tvalidation_0-mlogloss:0.42606\n","[24]\tvalidation_0-mlogloss:0.40868\n","[25]\tvalidation_0-mlogloss:0.39159\n","[26]\tvalidation_0-mlogloss:0.37536\n","[27]\tvalidation_0-mlogloss:0.36013\n","[28]\tvalidation_0-mlogloss:0.34661\n","[29]\tvalidation_0-mlogloss:0.33407\n","[30]\tvalidation_0-mlogloss:0.32248\n","[31]\tvalidation_0-mlogloss:0.31171\n","[32]\tvalidation_0-mlogloss:0.30142\n","[33]\tvalidation_0-mlogloss:0.29214\n","[34]\tvalidation_0-mlogloss:0.28373\n","[35]\tvalidation_0-mlogloss:0.27558\n","[36]\tvalidation_0-mlogloss:0.26789\n","[37]\tvalidation_0-mlogloss:0.26083\n","[38]\tvalidation_0-mlogloss:0.25495\n","[39]\tvalidation_0-mlogloss:0.24812\n","[40]\tvalidation_0-mlogloss:0.24271\n","[41]\tvalidation_0-mlogloss:0.23703\n","[42]\tvalidation_0-mlogloss:0.23129\n","[43]\tvalidation_0-mlogloss:0.22645\n","[44]\tvalidation_0-mlogloss:0.22182\n","[45]\tvalidation_0-mlogloss:0.21786\n","[46]\tvalidation_0-mlogloss:0.21340\n","[47]\tvalidation_0-mlogloss:0.20961\n","[48]\tvalidation_0-mlogloss:0.20622\n","[49]\tvalidation_0-mlogloss:0.20297\n","[50]\tvalidation_0-mlogloss:0.19921\n","[51]\tvalidation_0-mlogloss:0.19608\n","[52]\tvalidation_0-mlogloss:0.19326\n","[53]\tvalidation_0-mlogloss:0.19045\n","[54]\tvalidation_0-mlogloss:0.18825\n","[55]\tvalidation_0-mlogloss:0.18559\n","[56]\tvalidation_0-mlogloss:0.18341\n","[57]\tvalidation_0-mlogloss:0.18121\n","[58]\tvalidation_0-mlogloss:0.17932\n","[59]\tvalidation_0-mlogloss:0.17706\n","[60]\tvalidation_0-mlogloss:0.17485\n","[61]\tvalidation_0-mlogloss:0.17287\n","[62]\tvalidation_0-mlogloss:0.17134\n","[63]\tvalidation_0-mlogloss:0.16993\n","[64]\tvalidation_0-mlogloss:0.16849\n","[65]\tvalidation_0-mlogloss:0.16703\n","[66]\tvalidation_0-mlogloss:0.16562\n","[67]\tvalidation_0-mlogloss:0.16406\n","[68]\tvalidation_0-mlogloss:0.16272\n","[69]\tvalidation_0-mlogloss:0.16192\n","[70]\tvalidation_0-mlogloss:0.16091\n","[71]\tvalidation_0-mlogloss:0.15980\n","[72]\tvalidation_0-mlogloss:0.15890\n","[73]\tvalidation_0-mlogloss:0.15783\n","[74]\tvalidation_0-mlogloss:0.15681\n","[75]\tvalidation_0-mlogloss:0.15593\n","[76]\tvalidation_0-mlogloss:0.15522\n","[77]\tvalidation_0-mlogloss:0.15441\n","[78]\tvalidation_0-mlogloss:0.15338\n","[79]\tvalidation_0-mlogloss:0.15248\n","[80]\tvalidation_0-mlogloss:0.15194\n","[81]\tvalidation_0-mlogloss:0.15132\n","[82]\tvalidation_0-mlogloss:0.15077\n","[83]\tvalidation_0-mlogloss:0.14990\n","[84]\tvalidation_0-mlogloss:0.14915\n","[85]\tvalidation_0-mlogloss:0.14811\n","[86]\tvalidation_0-mlogloss:0.14738\n","[87]\tvalidation_0-mlogloss:0.14687\n","[88]\tvalidation_0-mlogloss:0.14618\n","[89]\tvalidation_0-mlogloss:0.14573\n","[90]\tvalidation_0-mlogloss:0.14539\n","[91]\tvalidation_0-mlogloss:0.14490\n","[92]\tvalidation_0-mlogloss:0.14460\n","[93]\tvalidation_0-mlogloss:0.14393\n","[94]\tvalidation_0-mlogloss:0.14345\n","[95]\tvalidation_0-mlogloss:0.14315\n","[96]\tvalidation_0-mlogloss:0.14268\n","[97]\tvalidation_0-mlogloss:0.14228\n","[98]\tvalidation_0-mlogloss:0.14206\n","[99]\tvalidation_0-mlogloss:0.14173\n","\n","📊 XGBoost Classification Report:\n","                                     precision    recall  f1-score   support\n","\n","               Apply security patch       0.92      1.00      0.96        58\n","                   Archive old logs       0.91      0.82      0.86        60\n","                   Block IP address       0.80      0.97      0.88        76\n","         Check database credentials       1.00      1.00      1.00        63\n","         Check network connectivity       0.93      0.79      0.86        53\n","              Clear temporary files       0.86      0.90      0.88        68\n","            Expand storage capacity       0.96      1.00      0.98        65\n","             Increase memory limits       0.98      1.00      0.99        54\n","             Inspect firewall rules       0.86      0.95      0.90        64\n","                   Investigate logs       0.96      0.65      0.77        74\n","        Investigate runaway process       1.00      1.00      1.00        74\n","                 No Action Required       1.00      1.00      1.00        54\n","          Optimize background tasks       1.00      0.97      0.98        58\n","          Optimize database queries       0.94      1.00      0.97        64\n","       Perform hardware diagnostics       0.95      1.00      0.97        78\n","                Restart application       0.99      0.99      0.99        71\n","         Restart application server       1.00      0.94      0.97        64\n","           Restart database service       1.00      0.95      0.97        78\n","           Restart network services       0.98      1.00      0.99        62\n","Restart services or scale resources       1.00      1.00      1.00        77\n","     Review heap memory allocations       1.00      0.98      0.99        60\n","           Rollback last deployment       0.97      1.00      0.98        65\n","            Scale compute resources       0.97      1.00      0.98        60\n","\n","                           accuracy                           0.95      1500\n","                          macro avg       0.96      0.95      0.95      1500\n","                       weighted avg       0.95      0.95      0.95      1500\n","\n"]}]},{"cell_type":"code","source":["\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# ----------------------------\n","# Step 1: Reshape Data and Split into Train/Validation\n","# ----------------------------\n","X_train_seq, X_val_seq, y_train_seq, y_val_seq = train_test_split(\n","    X_train_bal, y_train_bal, test_size=0.2, stratify=y_train_bal, random_state=42\n",")\n","\n","X_train_seq = X_train_seq.reshape((X_train_seq.shape[0], 1, X_train_seq.shape[1]))\n","X_val_seq = X_val_seq.reshape((X_val_seq.shape[0], 1, X_val_seq.shape[1]))\n","X_test_lstm = X_test_final.reshape((X_test_final.shape[0], 1, X_test_final.shape[1]))\n","\n","torch_X_train = torch.tensor(X_train_seq, dtype=torch.float32)\n","torch_y_train = torch.tensor(y_train_seq, dtype=torch.long)\n","torch_X_val = torch.tensor(X_val_seq, dtype=torch.float32)\n","torch_y_val = torch.tensor(y_val_seq, dtype=torch.long)\n","torch_X_test = torch.tensor(X_test_lstm, dtype=torch.float32)\n","torch_y_test = torch.tensor(y_test, dtype=torch.long)\n","\n","train_loader = DataLoader(TensorDataset(torch_X_train, torch_y_train), batch_size=64, shuffle=True)\n","val_loader = DataLoader(TensorDataset(torch_X_val, torch_y_val), batch_size=64, shuffle=False)\n","test_loader = DataLoader(TensorDataset(torch_X_test, torch_y_test), batch_size=64, shuffle=False)\n","\n","# ----------------------------\n","# Step 2: Define LSTM Model\n","# ----------------------------\n","class BalancedLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(BalancedLSTM, self).__init__()\n","        self.lstm = nn.LSTM(\n","            input_size=input_size,\n","            hidden_size=hidden_size,\n","            num_layers=1,\n","            batch_first=True,\n","            dropout=0.2,\n","            bidirectional=True\n","        )\n","        self.fc1 = nn.Linear(hidden_size * 2, 128)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.3)\n","        self.out = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out = out[:, -1, :]  # last timestep\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        return self.out(out)\n","\n","# ----------------------------\n","# Step 3: Setup\n","# ----------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","input_size = X_train_bal.shape[1]\n","hidden_size = 256\n","num_classes = len(np.unique(y_train_bal))\n","\n","model = BalancedLSTM(input_size, hidden_size, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n","\n","# ----------------------------\n","# Step 4: Training with Early Stopping\n","# ----------------------------\n","best_val_loss = float('inf')\n","patience = 7\n","patience_counter = 0\n","best_model_state = None\n","epochs = 200\n","\n","print(\"\\n🚀 Training with Early Stopping...\")\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    for batch_X, batch_y in train_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch_X)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    # Validation phase\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for val_X, val_y in val_loader:\n","            val_X, val_y = val_X.to(device), val_y.to(device)\n","            val_outputs = model(val_X)\n","            val_loss += criterion(val_outputs, val_y).item()\n","\n","    val_loss /= len(val_loader)\n","    scheduler.step()\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {total_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        patience_counter = 0\n","        best_model_state = model.state_dict()\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= patience:\n","            print(f\"⏹ Early stopping triggered at epoch {epoch+1}\")\n","            break\n","\n","# Load best model\n","if best_model_state:\n","    model.load_state_dict(best_model_state)\n","\n","# ----------------------------\n","# Step 5: Evaluation\n","# ----------------------------\n","model.eval()\n","y_pred_lstm = []\n","with torch.no_grad():\n","    for batch_X, _ in test_loader:\n","        batch_X = batch_X.to(device)\n","        outputs = model(batch_X)\n","        _, predicted = torch.max(outputs, 1)\n","        y_pred_lstm.extend(predicted.cpu().numpy())\n","\n","# ----------------------------\n","# Step 6: Metrics & Visualization\n","# ----------------------------\n","print(\"\\n📊 Classification Report (Test Set):\")\n","print(classification_report(y_test, y_pred_lstm, target_names=label_encoder.classes_))\n","print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred_lstm))\n","\n","\n","\n"],"metadata":{"id":"2m4JvMv_3ZnV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"771a7629-f558-4f1a-998d-db6609b352c5","executionInfo":{"status":"ok","timestamp":1752213234562,"user_tz":-330,"elapsed":775102,"user":{"displayName":"Utpal Patel","userId":"01434193021045546879"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","🚀 Training with Early Stopping...\n","Epoch 1/200, Train Loss: 108.2786, Val Loss: 1.0096\n","Epoch 2/200, Train Loss: 77.6969, Val Loss: 0.9626\n","Epoch 3/200, Train Loss: 72.8558, Val Loss: 0.8907\n","Epoch 4/200, Train Loss: 67.8620, Val Loss: 0.8383\n","Epoch 5/200, Train Loss: 63.1415, Val Loss: 0.7926\n","Epoch 6/200, Train Loss: 59.9424, Val Loss: 0.7733\n","Epoch 7/200, Train Loss: 58.1017, Val Loss: 0.7503\n","Epoch 8/200, Train Loss: 56.4612, Val Loss: 0.7234\n","Epoch 9/200, Train Loss: 54.5974, Val Loss: 0.7408\n","Epoch 10/200, Train Loss: 53.7029, Val Loss: 0.7028\n","Epoch 11/200, Train Loss: 51.0965, Val Loss: 0.6734\n","Epoch 12/200, Train Loss: 49.3719, Val Loss: 0.6592\n","Epoch 13/200, Train Loss: 49.0198, Val Loss: 0.6558\n","Epoch 14/200, Train Loss: 47.8559, Val Loss: 0.6599\n","Epoch 15/200, Train Loss: 47.4165, Val Loss: 0.6515\n","Epoch 16/200, Train Loss: 46.0806, Val Loss: 0.6286\n","Epoch 17/200, Train Loss: 46.1596, Val Loss: 0.6244\n","Epoch 18/200, Train Loss: 44.9205, Val Loss: 0.6111\n","Epoch 19/200, Train Loss: 44.0656, Val Loss: 0.6091\n","Epoch 20/200, Train Loss: 43.6817, Val Loss: 0.6054\n","Epoch 21/200, Train Loss: 41.5375, Val Loss: 0.5812\n","Epoch 22/200, Train Loss: 40.2951, Val Loss: 0.5707\n","Epoch 23/200, Train Loss: 39.9292, Val Loss: 0.5655\n","Epoch 24/200, Train Loss: 38.8536, Val Loss: 0.5559\n","Epoch 25/200, Train Loss: 38.2478, Val Loss: 0.5537\n","Epoch 26/200, Train Loss: 37.3762, Val Loss: 0.5383\n","Epoch 27/200, Train Loss: 36.6245, Val Loss: 0.5365\n","Epoch 28/200, Train Loss: 36.0304, Val Loss: 0.5289\n","Epoch 29/200, Train Loss: 35.5873, Val Loss: 0.5214\n","Epoch 30/200, Train Loss: 34.6814, Val Loss: 0.4976\n","Epoch 31/200, Train Loss: 32.9194, Val Loss: 0.4874\n","Epoch 32/200, Train Loss: 32.3755, Val Loss: 0.4856\n","Epoch 33/200, Train Loss: 31.6945, Val Loss: 0.4835\n","Epoch 34/200, Train Loss: 31.2426, Val Loss: 0.4783\n","Epoch 35/200, Train Loss: 31.0049, Val Loss: 0.4691\n","Epoch 36/200, Train Loss: 30.4863, Val Loss: 0.4703\n","Epoch 37/200, Train Loss: 29.9288, Val Loss: 0.4646\n","Epoch 38/200, Train Loss: 29.7258, Val Loss: 0.4657\n","Epoch 39/200, Train Loss: 29.2586, Val Loss: 0.4486\n","Epoch 40/200, Train Loss: 28.7617, Val Loss: 0.4546\n","Epoch 41/200, Train Loss: 28.3300, Val Loss: 0.4415\n","Epoch 42/200, Train Loss: 27.6372, Val Loss: 0.4460\n","Epoch 43/200, Train Loss: 27.4055, Val Loss: 0.4424\n","Epoch 44/200, Train Loss: 27.4632, Val Loss: 0.4362\n","Epoch 45/200, Train Loss: 27.1716, Val Loss: 0.4329\n","Epoch 46/200, Train Loss: 26.7965, Val Loss: 0.4368\n","Epoch 47/200, Train Loss: 26.7192, Val Loss: 0.4296\n","Epoch 48/200, Train Loss: 26.6216, Val Loss: 0.4241\n","Epoch 49/200, Train Loss: 26.6382, Val Loss: 0.4224\n","Epoch 50/200, Train Loss: 26.1618, Val Loss: 0.4200\n","Epoch 51/200, Train Loss: 25.6725, Val Loss: 0.4188\n","Epoch 52/200, Train Loss: 25.2241, Val Loss: 0.4170\n","Epoch 53/200, Train Loss: 25.4274, Val Loss: 0.4171\n","Epoch 54/200, Train Loss: 25.1076, Val Loss: 0.4144\n","Epoch 55/200, Train Loss: 25.1293, Val Loss: 0.4142\n","Epoch 56/200, Train Loss: 24.9250, Val Loss: 0.4139\n","Epoch 57/200, Train Loss: 24.7978, Val Loss: 0.4103\n","Epoch 58/200, Train Loss: 24.7639, Val Loss: 0.4117\n","Epoch 59/200, Train Loss: 24.4230, Val Loss: 0.4088\n","Epoch 60/200, Train Loss: 24.6917, Val Loss: 0.4087\n","Epoch 61/200, Train Loss: 24.2274, Val Loss: 0.4072\n","Epoch 62/200, Train Loss: 24.2037, Val Loss: 0.4068\n","Epoch 63/200, Train Loss: 24.3679, Val Loss: 0.4063\n","Epoch 64/200, Train Loss: 24.0885, Val Loss: 0.4074\n","Epoch 65/200, Train Loss: 24.1783, Val Loss: 0.4046\n","Epoch 66/200, Train Loss: 23.8500, Val Loss: 0.4047\n","Epoch 67/200, Train Loss: 24.1267, Val Loss: 0.4029\n","Epoch 68/200, Train Loss: 24.1246, Val Loss: 0.4024\n","Epoch 69/200, Train Loss: 23.9080, Val Loss: 0.4011\n","Epoch 70/200, Train Loss: 24.1120, Val Loss: 0.4031\n","Epoch 71/200, Train Loss: 24.0338, Val Loss: 0.4011\n","Epoch 72/200, Train Loss: 23.6804, Val Loss: 0.4012\n","Epoch 73/200, Train Loss: 23.8146, Val Loss: 0.4011\n","Epoch 74/200, Train Loss: 23.4363, Val Loss: 0.4009\n","Epoch 75/200, Train Loss: 23.6812, Val Loss: 0.4005\n","Epoch 76/200, Train Loss: 23.5889, Val Loss: 0.4007\n","Epoch 77/200, Train Loss: 23.4758, Val Loss: 0.3999\n","Epoch 78/200, Train Loss: 23.5276, Val Loss: 0.3993\n","Epoch 79/200, Train Loss: 23.4004, Val Loss: 0.3992\n","Epoch 80/200, Train Loss: 23.4220, Val Loss: 0.3998\n","Epoch 81/200, Train Loss: 23.3940, Val Loss: 0.3992\n","Epoch 82/200, Train Loss: 23.4632, Val Loss: 0.3990\n","Epoch 83/200, Train Loss: 23.4522, Val Loss: 0.3987\n","Epoch 84/200, Train Loss: 23.3341, Val Loss: 0.3983\n","Epoch 85/200, Train Loss: 23.3378, Val Loss: 0.3983\n","Epoch 86/200, Train Loss: 23.3588, Val Loss: 0.3983\n","Epoch 87/200, Train Loss: 23.3122, Val Loss: 0.3980\n","Epoch 88/200, Train Loss: 23.5143, Val Loss: 0.3980\n","Epoch 89/200, Train Loss: 23.1999, Val Loss: 0.3976\n","Epoch 90/200, Train Loss: 23.2325, Val Loss: 0.3973\n","Epoch 91/200, Train Loss: 23.5937, Val Loss: 0.3972\n","Epoch 92/200, Train Loss: 22.9655, Val Loss: 0.3972\n","Epoch 93/200, Train Loss: 23.1769, Val Loss: 0.3974\n","Epoch 94/200, Train Loss: 23.1257, Val Loss: 0.3973\n","Epoch 95/200, Train Loss: 23.2065, Val Loss: 0.3971\n","Epoch 96/200, Train Loss: 23.3419, Val Loss: 0.3972\n","Epoch 97/200, Train Loss: 23.2711, Val Loss: 0.3973\n","Epoch 98/200, Train Loss: 23.2478, Val Loss: 0.3971\n","Epoch 99/200, Train Loss: 23.4372, Val Loss: 0.3970\n","Epoch 100/200, Train Loss: 23.3065, Val Loss: 0.3969\n","Epoch 101/200, Train Loss: 23.2185, Val Loss: 0.3969\n","Epoch 102/200, Train Loss: 23.2471, Val Loss: 0.3969\n","Epoch 103/200, Train Loss: 23.3517, Val Loss: 0.3970\n","Epoch 104/200, Train Loss: 23.2234, Val Loss: 0.3968\n","Epoch 105/200, Train Loss: 22.9658, Val Loss: 0.3968\n","Epoch 106/200, Train Loss: 23.0333, Val Loss: 0.3968\n","Epoch 107/200, Train Loss: 23.1275, Val Loss: 0.3967\n","Epoch 108/200, Train Loss: 23.1586, Val Loss: 0.3967\n","Epoch 109/200, Train Loss: 23.5380, Val Loss: 0.3967\n","Epoch 110/200, Train Loss: 23.0116, Val Loss: 0.3967\n","Epoch 111/200, Train Loss: 22.9806, Val Loss: 0.3966\n","Epoch 112/200, Train Loss: 23.0180, Val Loss: 0.3966\n","Epoch 113/200, Train Loss: 23.3267, Val Loss: 0.3966\n","Epoch 114/200, Train Loss: 23.1986, Val Loss: 0.3966\n","Epoch 115/200, Train Loss: 22.9924, Val Loss: 0.3966\n","Epoch 116/200, Train Loss: 23.2083, Val Loss: 0.3965\n","Epoch 117/200, Train Loss: 22.9686, Val Loss: 0.3965\n","Epoch 118/200, Train Loss: 22.8241, Val Loss: 0.3964\n","Epoch 119/200, Train Loss: 23.1880, Val Loss: 0.3965\n","Epoch 120/200, Train Loss: 23.2219, Val Loss: 0.3964\n","Epoch 121/200, Train Loss: 23.0152, Val Loss: 0.3965\n","Epoch 122/200, Train Loss: 23.1548, Val Loss: 0.3965\n","Epoch 123/200, Train Loss: 23.1368, Val Loss: 0.3964\n","Epoch 124/200, Train Loss: 22.9931, Val Loss: 0.3964\n","Epoch 125/200, Train Loss: 23.1849, Val Loss: 0.3964\n","Epoch 126/200, Train Loss: 23.3749, Val Loss: 0.3964\n","Epoch 127/200, Train Loss: 23.0963, Val Loss: 0.3964\n","Epoch 128/200, Train Loss: 23.1980, Val Loss: 0.3964\n","Epoch 129/200, Train Loss: 23.0953, Val Loss: 0.3964\n","Epoch 130/200, Train Loss: 23.0463, Val Loss: 0.3964\n","Epoch 131/200, Train Loss: 23.2032, Val Loss: 0.3964\n","Epoch 132/200, Train Loss: 23.2488, Val Loss: 0.3964\n","Epoch 133/200, Train Loss: 23.0286, Val Loss: 0.3964\n","Epoch 134/200, Train Loss: 23.2007, Val Loss: 0.3964\n","Epoch 135/200, Train Loss: 23.1771, Val Loss: 0.3964\n","Epoch 136/200, Train Loss: 23.0561, Val Loss: 0.3964\n","Epoch 137/200, Train Loss: 22.9624, Val Loss: 0.3964\n","Epoch 138/200, Train Loss: 22.9547, Val Loss: 0.3964\n","Epoch 139/200, Train Loss: 23.3042, Val Loss: 0.3964\n","Epoch 140/200, Train Loss: 23.3102, Val Loss: 0.3964\n","Epoch 141/200, Train Loss: 22.9817, Val Loss: 0.3964\n","Epoch 142/200, Train Loss: 22.9560, Val Loss: 0.3963\n","Epoch 143/200, Train Loss: 23.0556, Val Loss: 0.3963\n","Epoch 144/200, Train Loss: 23.1996, Val Loss: 0.3963\n","Epoch 145/200, Train Loss: 23.0072, Val Loss: 0.3963\n","Epoch 146/200, Train Loss: 23.0311, Val Loss: 0.3963\n","Epoch 147/200, Train Loss: 23.0553, Val Loss: 0.3963\n","Epoch 148/200, Train Loss: 22.9311, Val Loss: 0.3963\n","Epoch 149/200, Train Loss: 23.1167, Val Loss: 0.3963\n","Epoch 150/200, Train Loss: 23.1357, Val Loss: 0.3963\n","Epoch 151/200, Train Loss: 23.0954, Val Loss: 0.3963\n","Epoch 152/200, Train Loss: 23.0515, Val Loss: 0.3963\n","Epoch 153/200, Train Loss: 22.9717, Val Loss: 0.3963\n","Epoch 154/200, Train Loss: 22.9490, Val Loss: 0.3963\n","Epoch 155/200, Train Loss: 23.0757, Val Loss: 0.3963\n","Epoch 156/200, Train Loss: 23.2681, Val Loss: 0.3963\n","Epoch 157/200, Train Loss: 22.8937, Val Loss: 0.3963\n","Epoch 158/200, Train Loss: 22.9527, Val Loss: 0.3963\n","Epoch 159/200, Train Loss: 23.2749, Val Loss: 0.3963\n","Epoch 160/200, Train Loss: 23.1085, Val Loss: 0.3963\n","Epoch 161/200, Train Loss: 22.9638, Val Loss: 0.3963\n","Epoch 162/200, Train Loss: 22.8821, Val Loss: 0.3963\n","Epoch 163/200, Train Loss: 23.1616, Val Loss: 0.3963\n","Epoch 164/200, Train Loss: 23.3277, Val Loss: 0.3963\n","Epoch 165/200, Train Loss: 22.7951, Val Loss: 0.3963\n","Epoch 166/200, Train Loss: 22.9569, Val Loss: 0.3963\n","Epoch 167/200, Train Loss: 23.1420, Val Loss: 0.3963\n","Epoch 168/200, Train Loss: 23.0469, Val Loss: 0.3963\n","Epoch 169/200, Train Loss: 23.0138, Val Loss: 0.3963\n","Epoch 170/200, Train Loss: 23.3373, Val Loss: 0.3963\n","Epoch 171/200, Train Loss: 23.1743, Val Loss: 0.3963\n","Epoch 172/200, Train Loss: 23.2214, Val Loss: 0.3963\n","Epoch 173/200, Train Loss: 23.0490, Val Loss: 0.3963\n","Epoch 174/200, Train Loss: 23.0519, Val Loss: 0.3963\n","Epoch 175/200, Train Loss: 23.0383, Val Loss: 0.3963\n","Epoch 176/200, Train Loss: 23.1278, Val Loss: 0.3963\n","Epoch 177/200, Train Loss: 22.9573, Val Loss: 0.3963\n","Epoch 178/200, Train Loss: 23.0264, Val Loss: 0.3963\n","Epoch 179/200, Train Loss: 23.1530, Val Loss: 0.3963\n","Epoch 180/200, Train Loss: 23.0843, Val Loss: 0.3963\n","Epoch 181/200, Train Loss: 23.2660, Val Loss: 0.3963\n","Epoch 182/200, Train Loss: 23.1996, Val Loss: 0.3963\n","Epoch 183/200, Train Loss: 23.2216, Val Loss: 0.3963\n","Epoch 184/200, Train Loss: 23.2641, Val Loss: 0.3963\n","Epoch 185/200, Train Loss: 23.0294, Val Loss: 0.3963\n","Epoch 186/200, Train Loss: 22.9772, Val Loss: 0.3963\n","Epoch 187/200, Train Loss: 23.1701, Val Loss: 0.3963\n","Epoch 188/200, Train Loss: 22.9604, Val Loss: 0.3963\n","Epoch 189/200, Train Loss: 23.0297, Val Loss: 0.3963\n","Epoch 190/200, Train Loss: 23.0719, Val Loss: 0.3963\n","Epoch 191/200, Train Loss: 22.9285, Val Loss: 0.3963\n","Epoch 192/200, Train Loss: 23.1148, Val Loss: 0.3963\n","Epoch 193/200, Train Loss: 23.1159, Val Loss: 0.3963\n","Epoch 194/200, Train Loss: 22.9139, Val Loss: 0.3963\n","Epoch 195/200, Train Loss: 22.8856, Val Loss: 0.3963\n","Epoch 196/200, Train Loss: 23.0040, Val Loss: 0.3963\n","Epoch 197/200, Train Loss: 22.9238, Val Loss: 0.3963\n","Epoch 198/200, Train Loss: 23.0221, Val Loss: 0.3963\n","Epoch 199/200, Train Loss: 22.9936, Val Loss: 0.3963\n","Epoch 200/200, Train Loss: 22.9909, Val Loss: 0.3963\n","\n","📊 Classification Report (Test Set):\n","                                     precision    recall  f1-score   support\n","\n","               Apply security patch       0.70      0.97      0.81        58\n","                   Archive old logs       0.68      0.57      0.62        60\n","                   Block IP address       0.77      0.97      0.86        76\n","         Check database credentials       0.95      1.00      0.98        63\n","         Check network connectivity       0.75      0.40      0.52        53\n","              Clear temporary files       0.66      0.69      0.68        68\n","            Expand storage capacity       0.86      0.95      0.91        65\n","             Increase memory limits       0.92      1.00      0.96        54\n","             Inspect firewall rules       0.66      0.89      0.75        64\n","                   Investigate logs       0.80      0.32      0.46        74\n","        Investigate runaway process       1.00      1.00      1.00        74\n","                 No Action Required       1.00      1.00      1.00        54\n","          Optimize background tasks       1.00      0.95      0.97        58\n","          Optimize database queries       0.85      0.95      0.90        64\n","       Perform hardware diagnostics       0.66      0.58      0.62        78\n","                Restart application       0.97      0.97      0.97        71\n","         Restart application server       0.56      0.66      0.60        64\n","           Restart database service       0.97      0.83      0.90        78\n","           Restart network services       0.97      1.00      0.98        62\n","Restart services or scale resources       0.75      0.74      0.75        77\n","     Review heap memory allocations       1.00      0.92      0.96        60\n","           Rollback last deployment       0.97      1.00      0.98        65\n","            Scale compute resources       0.95      1.00      0.98        60\n","\n","                           accuracy                           0.84      1500\n","                          macro avg       0.84      0.84      0.83      1500\n","                       weighted avg       0.84      0.84      0.83      1500\n","\n","✅ Accuracy: 0.8373333333333334\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","# For Random Forest\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","print(f\"✅ Random Forest Accuracy: {accuracy_rf:.4f}\")\n","\n","# For XGBoost\n","accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n","print(f\"✅ XGBoost Accuracy: {accuracy_xgb:.4f}\")\n","\n","# For LSTM\n","accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n","print(f\"✅ LSTM Accuracy: {accuracy_lstm:.4f}\")"],"metadata":{"id":"OeAZSdLLFLlz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752212321576,"user_tz":-330,"elapsed":32,"user":{"displayName":"Utpal Patel","userId":"01434193021045546879"}},"outputId":"4aa929a7-5547-482d-fd35-cf5a7479b330"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Random Forest Accuracy: 0.9453\n","✅ XGBoost Accuracy: 0.9520\n","✅ LSTM Accuracy: 0.8333\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report\n","\n","# ✅ 1. Decode LSTM predictions using LabelEncoder\n","test_df[\"Predicted_Suggested_Action\"] = label_encoder.inverse_transform(y_pred_lstm)\n","\n","# ✅ 2. Define initial expanded action explanations\n","expanded_action_mapping = {\n","    \"Investigate logs\": \"Reset credentials, check firewall settings, and review access logs\",\n","    \"Increase memory limits\": \"Scale application memory or optimize memory-intensive tasks\",\n","    \"Restart application\": \"Check logs for crash reason and restart the service/container\",\n","    \"Check database credentials\": \"Validate DB username/password and service connectivity\",\n","    \"No Action Required\": \"No immediate intervention needed\",\n","    \"Optimize background tasks\": \"Analyze and tune background jobs or schedulers\",\n","    \"Check network connectivity\": \"Ping upstream devices, test DNS resolution, verify firewall rules\",\n","    \"Apply security patch\": \"Patch vulnerabilities and restart affected services\",\n","    \"Expand storage capacity\": \"Increase disk allocation or mount additional storage volumes\",\n","    \"Clear temporary files\": \"Delete temporary files and clear application caches\",\n","    \"Restart services or scale resources\": \"Restart affected services or scale compute resources as needed\",\n","    \"Scale compute resources\": \"Provision additional CPU or memory to manage load spikes\",\n","    \"Rollback last deployment\": \"Revert to a stable application version and monitor system stability\",\n","    \"Inspect firewall rules\": \"Review and modify firewall settings to allow required traffic\",\n","    \"Restart application server\": \"Restart the web/application server and monitor its health\",\n","    \"Optimize database queries\": \"Identify and improve slow database queries\",\n","    \"Restart network services\": \"Restart network daemons and check connectivity\",\n","    \"Archive old logs\": \"Move old log files to long-term storage or delete them to free space\",\n","    \"Review heap memory allocations\": \"Analyze heap usage and optimize memory allocation\",\n","    \"Perform hardware diagnostics\": \"Run system-level diagnostics to identify potential hardware issues\",\n","    \"Block IP address\": \"Block suspicious IP addresses at the firewall or IDS/IPS level\",\n","    \"Investigate runaway process\": \"Identify and terminate processes consuming excessive resources\",\n","    \"Restart database service\": \"Restart the database service and verify data integrity\",\n","    \"Clean up disk\": \"Delete old logs, compress backups, or extend volume space\",\n","    \"Reboot system\": \"Ensure safe shutdown, check system logs, and restart hardware cleanly\",\n","    \"Update software package\": \"Run update commands and review changelog or dependency versions\",\n","    \"Check load balancer status\": \"Inspect load balancer health and traffic distribution logic\",\n","    \"Restart JVM\": \"Investigate heap usage and restart Java Virtual Machine service\",\n","    \"Review system configuration\": \"Validate config files for deprecated or misconfigured keys\",\n","    \"Restart container\": \"Stop and start the affected Docker/Kubernetes container\",\n","    \"Check certificate validity\": \"Renew expired certificates and reload services if needed\",\n","    \"Check disk IOPS\": \"Diagnose slow I/O operations using system metrics and SMART tools\",\n","    \"Scale horizontally\": \"Add more application instances or VMs to handle load\",\n","    \"Enable alerting\": \"Configure monitoring tools to trigger alerts on similar incidents\",\n","    \"Update firewall rules\": \"Adjust inbound/outbound firewall rules to allow expected traffic\",\n","    \"Check system time\": \"Verify NTP sync and timezone for consistent logging and SSL validity\",\n","}\n","\n","\n","\n","# ✅ 3. Auto-generate fallback description for new predicted actions\n","def generate_default_description(action_label):\n","    label = action_label.lower()\n","    if \"restart\" in label:\n","        return f\"Restart the component related to '{action_label}'\"\n","    elif \"check\" in label:\n","        return f\"Investigate system components and logs for '{action_label}'\"\n","    elif \"update\" in label:\n","        return f\"Ensure latest version of software or config for '{action_label}'\"\n","    elif \"clean\" in label or \"flush\" in label:\n","        return f\"Perform cleanup operation related to '{action_label}'\"\n","    elif \"investigate\" in label or \"review\" in label:\n","        return f\"Deep dive into '{action_label}' using monitoring and logging tools\"\n","    else:\n","        return f\"Perform appropriate diagnostic and resolution steps for '{action_label}'\"\n","\n","# ✅ 4. Extend mapping dynamically\n","unique_preds = test_df[\"Predicted_Suggested_Action\"].unique()\n","for pred in unique_preds:\n","    if pred not in expanded_action_mapping:\n","        expanded_action_mapping[pred] = generate_default_description(pred)\n","\n","# ✅ 5. Build backup (fallback) mapping from training data\n","fallback_mapping = (\n","    train_df.groupby(\"Suggested_Action\")[\"Suggested_Action\"]\n","    .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else \"⚠️ Needs Review\")\n","    .to_dict()\n",")\n","\n","# ✅ 6. Combine mappings into final function\n","def get_recommendation(pred_label):\n","    if pred_label in expanded_action_mapping:\n","        return expanded_action_mapping[pred_label]\n","    elif pred_label in fallback_mapping:\n","        return fallback_mapping[pred_label]\n","    else:\n","        return \"⚠️ Needs Review - Not Mapped\"\n","\n","# ✅ 7. Apply the logic\n","test_df[\"Recommended_Action\"] = test_df[\"Predicted_Suggested_Action\"].apply(get_recommendation)\n","\n","# ✅ 8. Train severity classifier using RF and XGB\n","X_severity_train = X_train_final\n","X_severity_test = X_test_final\n","\n","y_severity_train = train_df['Severity']\n","y_severity_test = test_df['Severity']\n","\n","# Encode severity labels\n","severity_encoder = LabelEncoder()\n","y_train_s = severity_encoder.fit_transform(y_severity_train)\n","y_test_s = severity_encoder.transform(y_severity_test)\n","\n","# Random Forest\n","rf_sev = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42)\n","rf_sev.fit(X_severity_train, y_train_s)\n","y_pred_rf_s = rf_sev.predict(X_severity_test)\n","\n","# XGBoost\n","xgb_sev = XGBClassifier(n_estimators=100, max_depth=6, eval_metric='mlogloss')\n","xgb_sev.fit(X_severity_train, y_train_s)\n","y_pred_xgb_s = xgb_sev.predict(X_severity_test)\n","\n","# ✅ 9. Predict severity for test_df using XGBoost\n","test_df[\"Predicted_Severity\"] = severity_encoder.inverse_transform(y_pred_xgb_s)\n","\n","# Display full column width in console\n","pd.set_option('display.max_colwidth', None)\n","pd.set_option('display.max_columns', None)\n","\n","# Print clean table with selected columns\n","display_cols = [\"Log_Message\", \"Predicted_Suggested_Action\", \"Recommended_Action\", \"Predicted_Severity\"]\n","\n","\n","from IPython.display import display, HTML\n","\n","# Subset of final DataFrame (10 rows)\n","preview_df = test_df[display_cols].head(20)\n","\n","# Rename columns with styled HTML headers (font-size: 16px or larger)\n","styled_cols = {\n","    \"Log_Message\": \"<span style='font-size:16px; font-weight:bold;'>Log Message</span>\",\n","    \"Predicted_Suggested_Action\": \"<span style='font-size:16px; font-weight:bold;'>Predicted Action</span>\",\n","    \"Recommended_Action\": \"<span style='font-size:16px; font-weight:bold;'>Recommended Action</span>\",\n","    \"Predicted_Severity\": \"<span style='font-size:16px; font-weight:bold;'>Predicted Severity</span>\",\n","}\n","\n","# Replace column names\n","preview_df.columns = [styled_cols[col] for col in preview_df.columns]\n","\n","# Display styled table\n","display(HTML(preview_df.to_html(escape=False, index=False)))\n","\n","\n","# ✅ 10. Save to CSV\n","test_df[[\"Log_Message\", \"Predicted_Suggested_Action\", \"Recommended_Action\", \"Predicted_Severity\"]].to_csv(\"final_lstm_action_mapping_with_severity.csv\", index=False)\n","\n","\n"],"metadata":{"id":"_gmp2aHi3hLn","colab":{"base_uri":"https://localhost:8080/","height":837},"executionInfo":{"status":"ok","timestamp":1752212381122,"user_tz":-330,"elapsed":59537,"user":{"displayName":"Utpal Patel","userId":"01434193021045546879"}},"outputId":"b477db11-320a-4f5c-c828-76912b1d09b2"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th><span style='font-size:16px; font-weight:bold;'>Log Message</span></th>\n","      <th><span style='font-size:16px; font-weight:bold;'>Predicted Action</span></th>\n","      <th><span style='font-size:16px; font-weight:bold;'>Recommended Action</span></th>\n","      <th><span style='font-size:16px; font-weight:bold;'>Predicted Severity</span></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>Network latency detected connecting to 192.168.1.140.</td>\n","      <td>Restart network services</td>\n","      <td>Restart network daemons and check connectivity</td>\n","      <td>Medium</td>\n","    </tr>\n","    <tr>\n","      <td>Low disk space alert: /var/log is 96.34% full.</td>\n","      <td>Clear temporary files</td>\n","      <td>Delete temporary files and clear application caches</td>\n","      <td>Medium</td>\n","    </tr>\n","    <tr>\n","      <td>Database connection error for UserDB. Status: MEM-EXC</td>\n","      <td>Optimize database queries</td>\n","      <td>Identify and improve slow database queries</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>No action required, routine log message: Normal operation</td>\n","      <td>No Action Required</td>\n","      <td>No immediate intervention needed</td>\n","      <td>Low</td>\n","    </tr>\n","    <tr>\n","      <td>No action required, routine log message: Routine check</td>\n","      <td>No Action Required</td>\n","      <td>No immediate intervention needed</td>\n","      <td>Low</td>\n","    </tr>\n","    <tr>\n","      <td>System unresponsive or freezing on Host_08.</td>\n","      <td>Restart application server</td>\n","      <td>Restart the web/application server and monitor its health</td>\n","      <td>Critical</td>\n","    </tr>\n","    <tr>\n","      <td>Network latency detected connecting to 192.168.1.142.</td>\n","      <td>Restart network services</td>\n","      <td>Restart network daemons and check connectivity</td>\n","      <td>Medium</td>\n","    </tr>\n","    <tr>\n","      <td>Memory usage spiking on application App_D. 94.90% used.</td>\n","      <td>Increase memory limits</td>\n","      <td>Scale application memory or optimize memory-intensive tasks</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>Network latency detected connecting to 192.168.1.183.</td>\n","      <td>Inspect firewall rules</td>\n","      <td>Review and modify firewall settings to allow required traffic</td>\n","      <td>Medium</td>\n","    </tr>\n","    <tr>\n","      <td>High CPU utilization on server Server_01. Current usage: 92.77%</td>\n","      <td>Scale compute resources</td>\n","      <td>Provision additional CPU or memory to manage load spikes</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>System unresponsive or freezing on Host_18.</td>\n","      <td>Perform hardware diagnostics</td>\n","      <td>Run system-level diagnostics to identify potential hardware issues</td>\n","      <td>Critical</td>\n","    </tr>\n","    <tr>\n","      <td>High CPU utilization on server Server_08. Current usage: 94.69%</td>\n","      <td>Scale compute resources</td>\n","      <td>Provision additional CPU or memory to manage load spikes</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>Suspicious login attempt from 10.0.0.42.</td>\n","      <td>Block IP address</td>\n","      <td>Block suspicious IP addresses at the firewall or IDS/IPS level</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>Authentication failed for user user_274 from 10.0.0.62.</td>\n","      <td>Investigate logs</td>\n","      <td>Reset credentials, check firewall settings, and review access logs</td>\n","      <td>Medium</td>\n","    </tr>\n","    <tr>\n","      <td>Database connection error for ArchiveDB. Status: CONN-RESET</td>\n","      <td>Check database credentials</td>\n","      <td>Validate DB username/password and service connectivity</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>No action required, routine log message: API call success</td>\n","      <td>No Action Required</td>\n","      <td>No immediate intervention needed</td>\n","      <td>Low</td>\n","    </tr>\n","    <tr>\n","      <td>Low disk space alert: /mnt/backup is 78.34% full.</td>\n","      <td>Expand storage capacity</td>\n","      <td>Increase disk allocation or mount additional storage volumes</td>\n","      <td>Medium</td>\n","    </tr>\n","    <tr>\n","      <td>Database connection error for ProdDB. Status: SQL-001</td>\n","      <td>Restart database service</td>\n","      <td>Restart the database service and verify data integrity</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>Network latency detected connecting to 192.168.1.165.</td>\n","      <td>Inspect firewall rules</td>\n","      <td>Review and modify firewall settings to allow required traffic</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <td>Low disk space alert: E: is 70.66% full.</td>\n","      <td>Clear temporary files</td>\n","      <td>Delete temporary files and clear application caches</td>\n","      <td>Medium</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}]},{"cell_type":"code","source":["import joblib\n","import torch\n","\n","# Save Random Forest & XGBoost models\n","joblib.dump(rf, \"rf_model.pkl\")\n","joblib.dump(xgb, \"xgb_model.pkl\")\n","\n","# Save the LSTM model (use torch.save for PyTorch)\n","torch.save(model.state_dict(), \"best_lstm_model.pth\")  # Save only the model parameters\n","\n","# Save Label Encoders\n","joblib.dump(label_encoder, \"label_encoder.pkl\")\n","joblib.dump(severity_encoder, \"severity_encoder.pkl\")\n","\n","# Save the Scalers\n","joblib.dump(scaler, \"scaler.pkl\")\n","joblib.dump(scaler_bert, \"scaler_bert.pkl\")  # optional, if you use separate scaler for BERT features\n"],"metadata":{"id":"N27UKPPmhjVw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752212381277,"user_tz":-330,"elapsed":135,"user":{"displayName":"Utpal Patel","userId":"01434193021045546879"}},"outputId":"679cc2eb-46ab-4a86-fafa-d2c07961a36e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['scaler_bert.pkl']"]},"metadata":{},"execution_count":7}]}]}